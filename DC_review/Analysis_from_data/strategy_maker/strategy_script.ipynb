{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JS0WWROWxDDw",
        "outputId": "afb6b15e-1485-4323-fa26-0a9276d9dd11"
      },
      "outputs": [],
      "source": [
        "# @title Step 1: Install Required Libraries (for Google Gemini)\n",
        "# This installs the libraries for Google Gemini, Google Search, reading Word documents, and handling images.\n",
        "!pip install -q \"google-generativeai\" \"google-search-results\" python-docx Pillow\n",
        "\n",
        "print(\"‚úÖ All required libraries for Google Gemini have been installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNfNXCqOxHhS",
        "outputId": "01356c1b-c68c-481e-99b5-e171d199ed71"
      },
      "outputs": [],
      "source": [
        "# @title Step 2: Enter Your API Keys\n",
        "import os\n",
        "from getpass import getpass\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Securely prompt for the Google AI API key\n",
        "try:\n",
        "  GOOGLE_API_KEY = getpass('Enter your Google AI Studio API key: ')\n",
        "  genai.configure(api_key=GOOGLE_API_KEY)\n",
        "  print(\"üîë Google Gemini API Key has been set.\")\n",
        "except Exception as e:\n",
        "  print(f\"Could not set Google API key: {e}\")\n",
        "\n",
        "\n",
        "# Securely prompt for the SerpApi API key\n",
        "try:\n",
        "  SERPAPI_API_KEY = getpass('Enter your SerpApi API key: ')\n",
        "  os.environ['SERPAPI_API_KEY'] = SERPAPI_API_KEY\n",
        "  print(\"üîë SerpApi API Key has been set.\")\n",
        "except Exception as e:\n",
        "  print(f\"Could not set SerpApi API key: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "QZWroBKSyjLi",
        "outputId": "1c944d0e-55f4-4506-e35e-2e870a3c75db"
      },
      "outputs": [],
      "source": [
        "# @title Step 3: Upload Your Document and Image Files\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your .docx analysis file and your .png/.jpg graph image.\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Confirm which files were uploaded\n",
        "print(\"\\n--- Uploaded Files ---\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"üìÑ {filename}\")\n",
        "print(\"--------------------\")\n",
        "print(\"\\n‚úÖ Files uploaded successfully. Please copy the exact filenames for the next step.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8_j5U4eyrao",
        "outputId": "0a4d9589-ac04-4f68-8fc4-4db01c290c9d"
      },
      "outputs": [],
      "source": [
        "# @title Step 4: Define the Analysis Functions (Using the High-Quota 'Flash' Model)\n",
        "import base64\n",
        "import docx\n",
        "from serpapi import GoogleSearch\n",
        "from IPython.display import display, Markdown\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "\n",
        "# --- HELPER FUNCTIONS ---\n",
        "\n",
        "def extract_text_from_docx(file_path):\n",
        "    try:\n",
        "        doc = docx.Document(file_path)\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs if para.text.strip() != \"\"])\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading docx file: {e}\")\n",
        "        return f\"Error reading docx file: {e}\"\n",
        "\n",
        "def fetch_real_time_data(queries: list):\n",
        "    print(\"Fetching real-time data from the web...\")\n",
        "    all_snippets = []\n",
        "    for query in queries:\n",
        "        try:\n",
        "            params = {\"engine\": \"google\", \"q\": query, \"api_key\": os.environ['SERPAPI_API_KEY']}\n",
        "            search = GoogleSearch(params)\n",
        "            results = search.get_dict()\n",
        "            snippet = results.get('organic_results', [{}])[0].get('snippet', 'No snippet found.')\n",
        "            all_snippets.append(f\"- {query}: {snippet}\")\n",
        "            print(f\"  - Found info for: {query}\")\n",
        "        except Exception as e:\n",
        "            all_snippets.append(f\"- Could not fetch info for '{query}': {e}\")\n",
        "    return \"\\n\".join(all_snippets)\n",
        "\n",
        "\n",
        "# --- REWRITTEN FUNCTION FOR GEMINI ---\n",
        "\n",
        "def generate_vlm_analysis(team_name, doc_text, image_paths: list, external_knowledge):\n",
        "    \"\"\"\n",
        "    Calls Google Gemini with text, MULTIPLE images, and real-time data to generate insights.\n",
        "    \"\"\"\n",
        "    print(\"\\nSending data to the Google Gemini Model for analysis...\")\n",
        "\n",
        "    # --- ‚¨áÔ∏è‚¨áÔ∏è THIS IS THE ONLY LINE THAT CHANGED ‚¨áÔ∏è‚¨áÔ∏è ---\n",
        "    # We are now using the 'flash' model, which has a much more generous free rate limit.\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "    # --- ‚¨ÜÔ∏è‚¨ÜÔ∏è END OF CHANGE ‚¨ÜÔ∏è‚¨ÜÔ∏è ---\n",
        "\n",
        "    prompt_content = f\"\"\"\n",
        "You are an expert digital strategist analyzing social media content for the IPL franchise: {team_name}.\n",
        "Your analysis should be a detailed, natural-language narrative. Synthesize all the information provided below.\n",
        "*1. Document-Based Analysis:*\n",
        "{doc_text}\n",
        "---\n",
        "*2. Real-Time Performance Data (IPL 2025):*\n",
        "{external_knowledge}\n",
        "---\n",
        "*3. Visual Data Analysis (Multiple Images):*\n",
        "The attached images contain key data visualizations. Please analyze all of them.\n",
        "*Your Task:*\n",
        "Synthesize all three sources to provide clear, strategic content recommendations. Structure your output with clear headings, tables for keywords, and bullet points.\n",
        "\"\"\"\n",
        "\n",
        "    input_for_gemini = [prompt_content]\n",
        "    print(\"Opening and preparing images for Gemini...\")\n",
        "    for image_path in image_paths:\n",
        "        try:\n",
        "            img = PIL.Image.open(image_path)\n",
        "            input_for_gemini.append(img)\n",
        "            print(f\"  - Image '{image_path}' prepared.\")\n",
        "        except Exception as e:\n",
        "            print(f\"  - Could not open or process image '{image_path}': {e}\")\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(input_for_gemini)\n",
        "        print(\"‚úÖ Analysis received from the Gemini Model!\")\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"\\n--- AN ERROR OCCURRED ---\")\n",
        "        print(f\"The call to the Gemini API failed. Error: {e}\")\n",
        "        return \"The analysis could not be generated due to an API error.\"\n",
        "\n",
        "\n",
        "print(\"‚úÖ All functions are now defined and ready to use (Google Gemini 'Flash' model enabled).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "O0QlM_Hgz2ZT",
        "outputId": "455e9690-5126-46fc-b2f8-105ad0d2c22c"
      },
      "outputs": [],
      "source": [
        "# @title ‚úèÔ∏è Step 5: Configure and Run Your Analysis!\n",
        "\n",
        "# --- 1. SET YOUR INPUTS HERE ---\n",
        "# (Make sure the filenames match what you uploaded in Step 3)\n",
        "team_to_analyze = \"DC\"\n",
        "document_path = \"DC_data_doc.docx\"\n",
        "\n",
        "# ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è  ADD ALL YOUR IMAGE FILENAMES TO THIS LIST  ‚¨áÔ∏è‚¨áÔ∏è‚¨áÔ∏è\n",
        "image_data_paths = [\n",
        "    \"image(1).png\",\n",
        "    \"image(2)).png\", # Example: add your second image file name\n",
        "    \"image(3).png\", # Example: add your third image file name\n",
        "    \"image(4).png\"\n",
        "]\n",
        "# ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è  ENSURE THE FILENAMES ABOVE ARE CORRECT  ‚¨ÜÔ∏è‚¨ÜÔ∏è‚¨ÜÔ∏è\n",
        "\n",
        "# (Customize these search queries for the team's key players/topics)\n",
        "real_time_queries = [\n",
        "    f\"KL Rahul performance in IPL 2025\",\n",
        "    f\"Axar patel captaincy in IPL 2025\",\n",
        "    f\"{team_to_analyze} team news 2025\"\n",
        "]\n",
        "\n",
        "# --- 2. THE SCRIPT WILL RUN FROM HERE ---\n",
        "print(f\"üöÄ Starting analysis for {team_to_analyze} with {len(image_data_paths)} images...\")\n",
        "\n",
        "# Extract text from the local document\n",
        "document_content = extract_text_from_docx(document_path)\n",
        "\n",
        "# Fetch fresh information from the internet\n",
        "real_time_content = fetch_real_time_data(real_time_queries)\n",
        "\n",
        "# Call the VLM with all the context to generate the final analysis\n",
        "# Note: We now pass the list image_data_paths to the function\n",
        "final_insights = generate_vlm_analysis(\n",
        "    team_name=team_to_analyze,\n",
        "    doc_text=document_content,\n",
        "    image_paths=image_data_paths, # Passing the list of image paths\n",
        "    external_knowledge=real_time_content\n",
        ")\n",
        "\n",
        "# --- 3. SAVE THE OUTPUT TO A FILE ---\n",
        "report_filename = f\"{team_to_analyze}_strategy_report.md\"\n",
        "with open(report_filename, \"w\") as f:\n",
        "    f.write(final_insights)\n",
        "\n",
        "print(f\"\\n‚ú® Success! Your report is ready and saved as '{report_filename}'.\")\n",
        "print(\"You can view the formatted output in the next cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yn6MNytF0UIV",
        "outputId": "98c44ab2-d68e-4f31-d409-901cd9963af8"
      },
      "outputs": [],
      "source": [
        "# @title üìä Step 6: View and Download the Generated Report\n",
        "\n",
        "# Display the report with Markdown formatting for better readability\n",
        "print(\"--- GENERATED STRATEGIC INSIGHTS ---\")\n",
        "display(Markdown(final_insights))\n",
        "\n",
        "# Provide a link to download the saved file\n",
        "from google.colab import files\n",
        "print(f\"\\n\\n--- Download Your Report ---\")\n",
        "print(f\"Click the link below to download the report file '{report_filename}'.\")\n",
        "files.download(report_filename)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
